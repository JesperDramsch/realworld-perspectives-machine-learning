<!--
.. title: Why and how make ML reproducible?
.. slug: why-and-how-make-ml-reproducible
.. date: 2022-12-02 13:05:00 UTC+01:00
.. tags: 
.. category: 
.. link: 
.. description: 
.. type: text
.. author: Jesper Dramsch
-->

The overview talk serves to set the scene and present different areas where researchers can increase the quality of their research artefacts that use ML. These increases in quality are achieved by using existing solutions to minimize the impact these methods take on researcher productivity. 

This talk loosely covers the topics Jesper discussed in their Euroscipy tutorial which will be used for the interactive session here:

[https://github.com/JesperDramsch/euroscipy-2022-ml-for-science-reproducibility-tutorial](https://github.com/JesperDramsch/euroscipy-2022-ml-for-science-reproducibility-tutorial) 

Topics covered:

1. Why make it reproducible?
2. Model Evaluation
3. Benchmarking
4. Model Sharing
5. Testing ML Code
6. Interpretability
7. Ablation Studies

These topics are used as examples of “easy wins” researchers can implement to disproportionately improve the quality of their research output with minimal additional work using existing libraries and reusable code snippets.
